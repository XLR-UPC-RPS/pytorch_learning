{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "075d507d",
   "metadata": {},
   "source": [
    "# The pre-kownedeges I need to learn   \n",
    "### 1.Introduction\n",
    "**FiLM EfficientNet**    \n",
    "Its function is to intgrate the semantic information of language instructions into the visual feature extrction process.This enables the convolutional network to focus on target objects in the image according to the given instructions.  \n",
    "\n",
    "**TokenLearner**  \n",
    "It can filter key information from redundant visual features and compress them into a small number of tokens  \n",
    "\n",
    "**Tansformer**    \n",
    "Unlike models with complex recurrent or convolutional structures,the Transformer achieves efficient learning through parallel computing and the attention mechanism.\n",
    "### 3.Preliminaies  \n",
    "**·What's the meaning of action disreibuton $\\pi(· | i, x_0) $ ?**  \n",
    "The explanation of AI: $·$ represents any candidate action, $i$(language instruction) and $\\{x_j\\}^t_{j=0}$(historical visual instruction) are coniditions, meaning this probability distribution is generated by the policy based on the current instruction and the observed images.   \n",
    "**·Behavioral Cloning and Negative Log-Likehood,NLL**  \n",
    "The core optimization objective of behavioral cloning is to make the action probability distribution output by the policy $π$\n",
    " match the action distribution of expert demonstrations as closely as possible. Its loss function is constructed based on the Negative Log-Likelihood (NLL).**The core assumption is maximize the likelihood of expert actions**,for a single timestep $t$ of a single sample, the **log-likelihook** of the expert action $a_t^{(n)}$is:  \n",
    " $$\n",
    " log(a_t^{(n)} | i^{(n)},\\{x_j^{(n)}\\}^t_{j=0})\n",
    " $$  \n",
    "To optimize the policy performance across the entire dataset, we need to **maximize the sum of log-likelihoods for all expert actions across all timesteps of all samples**. The objective function is defined as:\n",
    "$$\n",
    "L_{ll} = \\frac{1}{M}\\sum_{n=0}^{N} \\sum_{t=0}^{T^{(n)}} log(a_t^{(n)} | i^{(n)},\\{x_j^{(n)}\\}^t_{j=0})\n",
    "$$  \n",
    "解释一下上述式子：  \n",
    "内层求和代表遍历单个回合的所有时间步，外层求和是遍历数据集中的所有回合（当时不理解外层求和的原因是没有想到这个解释一上来就给得非常得一般化，一个回合可以是一个任务比如“拿起杯子”、“打开抽屉”）。$M = \\sum_{n=0}^N$是总时间步数，用于归一化，使得目标函数的取值不受数据集大小、回合长度的影响  \n",
    "The Negative Log-likelihook can be defined as following:  \n",
    "$$\n",
    "L_{BC} = -\\frac{1}{M}\\sum_{n=0}^{N} \\sum_{t=0}^{T^{(n)}} log(a_t^{(n)} | i^{(n)},\\{x_j^{(n)}\\}^t_{j=0})\n",
    "$$  \n",
    "The training process adjusts the network parameters of policy $π$ through gradient descent, continuously reducing \n",
    "$L_{BC}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52473be0",
   "metadata": {},
   "source": [
    "# 5.MODEL  \n",
    "### **·How the $9 \\times 9 \\times 512$ feature map is derived ?**  \n",
    "The input fo the EfficientNet-B3 model is 6 $300 \\times 300$images.EfficientNet-B3 rudece the spatial size of the feature map while incteasing the number of feature channels.Each **downsampling** step halves the spatial dimensionof the feature map.(下采样：步缩小特征图的空间尺寸，同时提升特征的语义表达能力，最终被压缩为$9 \\times 9$)   \n",
    "**Channel dimension (512)**: This dimension corresponds to the semantic feature information of the image  \n",
    "### **How does FFiLM and EfficinttNet-B3 cooperate with each other?**   \n",
    "FiLM 不会改变 EfficientNet-B3 的网络结构，而是在其特征提取过程中 “插入” 语言指令的引导信号，具体操作是对 EfficientNet-B3 中间层的特征张量执行逐通道的**线性变换**（真的只是线性变换吗？我再去文章里找找）,最终实现让语言指令的语义信息引导 EfficientNet-B3 的视觉特征提取  \n",
    "### **What's the feature map flattening and what's the difference between flattening and image patchificaiton?**    \n",
    "**Image patchfication** refers ti directly splitting the original image into fixed-size patches(e.g.,$16 \\times 16$). This method retains a large amount of redundent（冗余的） information from the original image.  \n",
    "**Feature map lattening**: After we get the high-dimensional semantic feature of the image through a convolutional network(e.g., the $9 \\times 9 \\times 512$ spatail map,if we see it as a $9 \\times 9$ 2D feature map(each feature contains a 512 dimension vecctor)),we could flatten it into a 1D sequence(81 tockens).This appoach reduce the number of tokens while prevserving task-relevant features, which is the core method of RT-1 to achieve **compact tokenization**  \n",
    "### **The structure of EfficientNet-B3**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d3b7b",
   "metadata": {},
   "source": [
    "# Key Points  \n",
    "## 1.How to use transformers?  \n",
    "Tranformers were oringinally desighed for text sequences, if we want to us it to train the robot ,in which the condition is not the same as the input(instruction and observed images) and output(actions) are not text. The authors parameterized $\\pi$(repesent the policy) by first mapping inputs $i,\\{x_j\\}^t_{j=0}$ to a sequence $\\{ \\xi_h \\}^H_{h=0}$ and aciton outputs $a_t$ to a sequence $\\{y_k\\}^K_{k=0}$ before using a Transfomer to learn the mapping $\\{ \\xi_h \\}^H_{h=0}$ $→ $ $\\{y_k\\}^K_{k=0}$    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0663c2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
